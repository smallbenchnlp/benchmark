### Small-Bench NLP: Benchmark for small single GPU trained models in Natural Language Processing

Small-Bench NLP, is a benchmark for small efficient neural language models trained on a single GPU. The benchmark comprises of eight NLP tasks on the publicly available [GLUE] (https://arxiv.org/pdf/1804.07461.pdf) datasets and a leaderboard to track the progress of the community.

***Models and Code will be published very soon. Thanks for being patient with us.*** 

### Contact us

Meanwhile, if you have any questions, you can reach out to us at smallbenchnlp@gmail.com.

### Citation 
To read more about Small-Benclh NLP benchmark paper, click [here](https://arxiv.org/abs/2109.10847). 

To cite our paper -
```
@misc{kanakarajan2021smallbench,
      title={Small-Bench NLP: Benchmark for small single GPU trained models in Natural Language Processing}, 
      author={Kamal Raj Kanakarajan and Bhuvana Kundumani and Malaikannan Sankarasubbu},
      year={2021},
      eprint={2109.10847},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```
